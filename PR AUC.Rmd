## First Level Models - ROC, PR Curves and AUC

Using the PR curves and their AUC, we can see the stability of different models balance of sensitivity and specificity throughout different thresholds. Because our TARGET class is very unbalanced, we should value the PR's AUC to find our best initial model. 

```{r}
pos_label <- "1"

labels <- as.numeric(as.character(test_processed$TARGET))

log_pred <- as.numeric(log_pred)
las_pred <- as.numeric(las_pred)
knn_pred <- as.numeric(knn_pred)
svm_pred <- as.numeric(svm_pred)
dt_pred  <- as.numeric(dt_pred)
rf_pred  <- as.numeric(rf_pred)
ann_pred <- as.numeric(ann_pred)

stopifnot(
  length(labels) == length(log_pred),
  length(labels) == length(las_pred),
  length(labels) == length(knn_pred),
  length(labels) == length(svm_pred),
  length(labels) == length(dt_pred),
  length(labels) == length(rf_pred),
  length(labels) == length(ann_pred)
)

scores <- list(
  Logistic = log_pred,
  LASSO    = las_pred,
  KNN      = knn_pred,
  ANN      = ann_pred,
  Tree     = dt_pred,
  SVM      = svm_pred,
  RF       = rf_pred
)

mmod <- mmdata(scores, labels, modnames = names(scores), posclass = 1)
eval <- evalmod(mmod)
autoplot(eval)

cat("Because the target variable is quite sparse, our best model will be based off of PR AUC, and not ROC AUC\n")
cat("As seen from the plot, Logistic and LASSO seem to be the highest performing models.\n")
```

